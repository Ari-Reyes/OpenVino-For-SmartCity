{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Face Detection Sample\n",
    "\n",
    "This sample showcases Object Detection task applied for face recognition using sequence of neural networks.\n",
    "Async API usage can improve overall frame-rate of the application, because rather than wait for inference to complete,\n",
    "the application can continue operating on the host while accelerator is busy.\n",
    "This sample maintains three parallel infer requests for the Age/Gender Recognition, Head Pose Estimation, and Emotions Recognition that run simultaneously.\n",
    "\n",
    "Other sample objectives are:\n",
    "\n",
    "*\tVideo as input support via OpenCV\n",
    "*\tVisualization of the resulting face bounding boxes from Face Detection network\n",
    "*\tVisualization of age/gender, head pose and emotion information for each detected face\n",
    "\n",
    "OpenCV is used to draw resulting bounding boxes, labels, and other information. You can copy and paste this code without pulling Inference Engine sample helpers into your application\n",
    "\n",
    "## How it Works\n",
    "\n",
    "*\tThe application reads command line parameters and loads up to four networks depending on `-m...` options family to the Inference Engine.\n",
    "*\tThe application gets a frame from the OpenCV's VideoCapture.\n",
    "*\tThe application performs inference on the frame detection network.\n",
    "*\tThe application performs three simultaneous inferences, using the Age/Gender, Head Pose and Emotions detection networks if they are specified in command line.\n",
    "*\tThe application displays the results.\n",
    "\n",
    "The new Async API operates with a new notion of the Infer Request that encapsulates the inputs/outputs and separates scheduling and waiting for result. For more information about Async API and the difference between Sync and Async modes performance, refer to **How it Works** and **Async API** sections in [Object Detection SSD, Async API Performance Showcase Sample](@ref InferenceEngineObjectDetectionSSDDemoAsyncApplication).\n",
    "\n",
    "\n",
    "## Compiling\n",
    "\n",
    "There are two source files: \n",
    "* [detectors.cpp](detectors.cpp) -- contains the various helper functions\n",
    "* [main.cpp](main.cpp) -- contains the main loop\n",
    "\n",
    "We have provided a Makefile for compiling the application. Run the following cell to run the make command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path().resolve().parent.parent))\n",
    "from demoTools.demoutils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- The C compiler identification is GNU 5.4.0\n",
      "-- The CXX compiler identification is GNU 5.4.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- InferenceEngine_DIR=/opt/intel//computer_vision_sdk_2018.5.445/deployment_tools/inference_engine/share\n",
      "-- CMAKE_MODULE_PATH=/opt/intel//computer_vision_sdk_2018.5.445/deployment_tools/inference_engine/share/../samples/cmake\n",
      "-- Looking for inference engine configuration file at: /home/u25335/Reference-samples/iot-devcloud/cpp/share\n",
      "-- /etc/*-release distrib: Ubuntu 16.04\n",
      "-- Found InferenceEngine: /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/inference_engine/lib/ubuntu_16.04/intel64/libinference_engine.so (Required is at least version \"1.0\") \n",
      "-- Performing Test HAVE_CPUID_INFO\n",
      "-- Performing Test HAVE_CPUID_INFO - Success\n",
      "-- Host CPU features:\n",
      "--   3DNOW not supported\n",
      "--   3DNOWEXT not supported\n",
      "--   ABM not supported\n",
      "--   ADX supported\n",
      "--   AES supported\n",
      "--   AVX supported\n",
      "--   AVX2 supported\n",
      "--   AVX512CD supported\n",
      "--   AVX512F supported\n",
      "--   AVX512ER not supported\n",
      "--   AVX512PF not supported\n",
      "--   BMI1 supported\n",
      "--   BMI2 supported\n",
      "--   CLFSH supported\n",
      "--   CMPXCHG16B supported\n",
      "--   CX8 supported\n",
      "--   ERMS supported\n",
      "--   F16C supported\n",
      "--   FMA supported\n",
      "--   FSGSBASE supported\n",
      "--   FXSR supported\n",
      "--   HLE supported\n",
      "--   INVPCID supported\n",
      "--   LAHF supported\n",
      "--   LZCNT supported\n",
      "--   MMX supported\n",
      "--   MMXEXT not supported\n",
      "--   MONITOR supported\n",
      "--   MOVBE supported\n",
      "--   MSR supported\n",
      "--   OSXSAVE supported\n",
      "--   PCLMULQDQ supported\n",
      "--   POPCNT supported\n",
      "--   PREFETCHWT1 not supported\n",
      "--   RDRAND supported\n",
      "--   RDSEED supported\n",
      "--   RDTSCP supported\n",
      "--   RTM supported\n",
      "--   SEP supported\n",
      "--   SHA not supported\n",
      "--   SSE supported\n",
      "--   SSE2 supported\n",
      "--   SSE3 supported\n",
      "--   SSE4.1 supported\n",
      "--   SSE4.2 supported\n",
      "--   SSE4a not supported\n",
      "--   SSSE3 supported\n",
      "--   SYSCALL supported\n",
      "--   TBM not supported\n",
      "--   XOP not supported\n",
      "--   XSAVE supported\n",
      "-- OMP Release lib: /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/inference_engine/external/omp/lib/libiomp5.so\n",
      "-- OMP Debug lib: /opt/intel/computer_vision_sdk_2018.5.445/deployment_tools/inference_engine/external/omp/lib/libiomp5.so\n",
      "-- CMAKE_BUILD_TYPE not defined, 'Release' will be used\n",
      "-- Found OpenCV: /opt/intel/computer_vision_sdk_2018.5.445/opencv (found version \"4.0.1\") \n",
      "-- Looking for C++ include unistd.h\n",
      "-- Looking for C++ include unistd.h - found\n",
      "-- Looking for C++ include stdint.h\n",
      "-- Looking for C++ include stdint.h - found\n",
      "-- Looking for C++ include inttypes.h\n",
      "-- Looking for C++ include inttypes.h - found\n",
      "-- Looking for C++ include sys/types.h\n",
      "-- Looking for C++ include sys/types.h - found\n",
      "-- Looking for C++ include sys/stat.h\n",
      "-- Looking for C++ include sys/stat.h - found\n",
      "-- Looking for C++ include fnmatch.h\n",
      "-- Looking for C++ include fnmatch.h - found\n",
      "-- Looking for C++ include stddef.h\n",
      "-- Looking for C++ include stddef.h - found\n",
      "-- Check size of uint32_t\n",
      "-- Check size of uint32_t - done\n",
      "-- Looking for strtoll\n",
      "-- Looking for strtoll - found\n",
      "-- OPENCV is enabled\n",
      "-- OpenCV_INCLUDE_DIRS=/opt/intel/computer_vision_sdk_2018.5.445/opencv/include\n",
      "-- OpenCV_LIBS=opencv_videoio;opencv_stitching;opencv_ml;opencv_highgui;opencv_objdetect;opencv_dnn;opencv_calib3d;opencv_flann;opencv_imgproc;opencv_features2d;opencv_gapi;opencv_video;opencv_photo;opencv_imgcodecs;opencv_core;opencv_pvl;opencv_videoio;opencv_stitching;opencv_ml;opencv_highgui;opencv_objdetect;opencv_dnn;opencv_calib3d;opencv_flann;opencv_imgproc;opencv_features2d;opencv_gapi;opencv_video;opencv_photo;opencv_imgcodecs;opencv_core;opencv_pvl\n",
      "-- Looking for pthread.h\n",
      "-- Looking for pthread.h - found\n",
      "-- Looking for pthread_create\n",
      "-- Looking for pthread_create - not found\n",
      "-- Looking for pthread_create in pthreads\n",
      "-- Looking for pthread_create in pthreads - not found\n",
      "-- Looking for pthread_create in pthread\n",
      "-- Looking for pthread_create in pthread - found\n",
      "-- Found Threads: TRUE  \n",
      "-- Boost version: 1.58.0\n",
      "-- Found the following Boost libraries:\n",
      "--   log\n",
      "--   system\n",
      "--   filesystem\n",
      "--   log_setup\n",
      "--   date_time\n",
      "--   thread\n",
      "--   regex\n",
      "--   chrono\n",
      "--   atomic\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/u25335/Reference-samples/iot-devcloud/cpp/OpenVino-For-SmartCity/build\n"
     ]
    }
   ],
   "source": [
    "!mkdir build && cd build && . ../scripts/setupenv.sh && cmake .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mScanning dependencies of target gflags_nothreads_static\u001b[0m\n",
      "[  2%] \u001b[32mBuilding CXX object gflags/CMakeFiles/gflags_nothreads_static.dir/src/gflags.cc.o\u001b[0m\n",
      "[  5%] \u001b[32mBuilding CXX object gflags/CMakeFiles/gflags_nothreads_static.dir/src/gflags_reporting.cc.o\u001b[0m\n",
      "[  7%] \u001b[32mBuilding CXX object gflags/CMakeFiles/gflags_nothreads_static.dir/src/gflags_completions.cc.o\u001b[0m\n",
      "[ 10%] \u001b[32m\u001b[1mLinking CXX static library ../intel64/Release/lib/libgflags_nothreads.a\u001b[0m\n",
      "[ 10%] Built target gflags_nothreads_static\n",
      "\u001b[35m\u001b[1mScanning dependencies of target format_reader\u001b[0m\n",
      "[ 12%] \u001b[32mBuilding CXX object format_reader/CMakeFiles/format_reader.dir/format_reader.cpp.o\u001b[0m\n",
      "[ 15%] \u001b[32mBuilding CXX object format_reader/CMakeFiles/format_reader.dir/bmp.cpp.o\u001b[0m\n",
      "[ 17%] \u001b[32mBuilding CXX object format_reader/CMakeFiles/format_reader.dir/opencv_wraper.cpp.o\u001b[0m\n",
      "[ 20%] \u001b[32mBuilding CXX object format_reader/CMakeFiles/format_reader.dir/MnistUbyte.cpp.o\u001b[0m\n",
      "[ 22%] \u001b[32m\u001b[1mLinking CXX shared library ../intel64/Release/lib/libformat_reader.so\u001b[0m\n",
      "[ 22%] Built target format_reader\n",
      "\u001b[35m\u001b[1mScanning dependencies of target ie_cpu_extension\u001b[0m\n",
      "[ 25%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_reorg_yolo.cpp.o\u001b[0m\n",
      "[ 27%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_simplernms.cpp.o\u001b[0m\n",
      "[ 30%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_psroi.cpp.o\u001b[0m\n",
      "[ 32%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_region_yolo.cpp.o\u001b[0m\n",
      "[ 35%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_mvn.cpp.o\u001b[0m\n",
      "[ 37%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_priorbox.cpp.o\u001b[0m\n",
      "[ 40%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_gather.cpp.o\u001b[0m\n",
      "[ 42%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/simple_copy.cpp.o\u001b[0m\n",
      "[ 45%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_argmax.cpp.o\u001b[0m\n",
      "[ 47%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_pad.cpp.o\u001b[0m\n",
      "[ 50%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_grn.cpp.o\u001b[0m\n",
      "[ 52%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_list.cpp.o\u001b[0m\n",
      "[ 55%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_interp.cpp.o\u001b[0m\n",
      "[ 57%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_base.cpp.o\u001b[0m\n",
      "[ 60%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_ctc_greedy.cpp.o\u001b[0m\n",
      "[ 62%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_priorbox_clustered.cpp.o\u001b[0m\n",
      "[ 65%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_detectionoutput.cpp.o\u001b[0m\n",
      "[ 67%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_spatial_transformer.cpp.o\u001b[0m\n",
      "[ 70%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_proposal.cpp.o\u001b[0m\n",
      "[ 72%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_resample.cpp.o\u001b[0m\n",
      "[ 75%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_normalize.cpp.o\u001b[0m\n",
      "[ 77%] \u001b[32mBuilding CXX object ie_cpu_extension/CMakeFiles/ie_cpu_extension.dir/ext_powerfile.cpp.o\u001b[0m\n",
      "[ 80%] \u001b[32m\u001b[1mLinking CXX shared library libcpu_extension.so\u001b[0m\n",
      "[ 80%] Built target ie_cpu_extension\n",
      "\u001b[35m\u001b[1mScanning dependencies of target smart_city_tutorial\u001b[0m\n",
      "[ 82%] \u001b[32mBuilding CXX object CMakeFiles/smart_city_tutorial.dir/src/base_detection.cpp.o\u001b[0m\n",
      "[ 85%] \u001b[32mBuilding CXX object CMakeFiles/smart_city_tutorial.dir/src/main.cpp.o\u001b[0m\n",
      "[ 87%] \u001b[32mBuilding CXX object CMakeFiles/smart_city_tutorial.dir/src/yolo_labels.cpp.o\u001b[0m\n",
      "[ 90%] \u001b[32mBuilding CXX object CMakeFiles/smart_city_tutorial.dir/src/object_detection.cpp.o\u001b[0m\n",
      "[ 92%] \u001b[32mBuilding CXX object CMakeFiles/smart_city_tutorial.dir/src/Tracker.cpp.o\u001b[0m\n",
      "[ 95%] \u001b[32mBuilding CXX object CMakeFiles/smart_city_tutorial.dir/src/yolo_detection.cpp.o\u001b[0m\n",
      "[ 97%] \u001b[32mBuilding CXX object CMakeFiles/smart_city_tutorial.dir/src/drawer.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX executable intel64/Release/smart_city_tutorial\u001b[0m\n",
      "[100%] Built target smart_city_tutorial\n"
     ]
    }
   ],
   "source": [
    "!cd build && make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This produces an executable [face_detector](). This executable takes in a number of different command line arguments.\n",
    "\n",
    "Run the following cell to see the list: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp build/intel64/Release/smart_city_tutorial ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 2: ./smart_city_tutorial: No such file or directory\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/data/reference-sample-data/extension/ \\n./smart_city_tutorial -h\\n'' returned non-zero exit status 127",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9f8e272a97f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/data/reference-sample-data/extension/ \\n./smart_city_tutorial -h\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2345\u001b[0m                 \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2346\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2347\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2348\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/h/.local/lib/python3.5/site-packages/decorator.py:decorator-gen-110>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/data/reference-sample-data/extension/ \\n./smart_city_tutorial -h\\n'' returned non-zero exit status 127"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/data/reference-sample-data/extension/ \n",
    "./smart_city_tutorial -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The version of the cpp file here is a slightly modified version of the faca_detector code built-in to the the Intel® Distribution of OpenVINO™ toolkit.\n",
    "In this version, the result is written into a output mp4 file specified by the `-o` flag. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the inference\n",
    "\n",
    "Now we are ready to run the inference workload. In this step we will be submitting the workload as a job to the job queue.\n",
    "\n",
    "Currently, you are on what is called a \"devnode\". On this system, you are allocated just one core on a large Intel® Xeon® CPU. The purpose of this node is to develop code on the devnode and run minimal sections of Jupyter* Notebooks, but it is not meant for compute intensive jobs like deep learning inference. So we need to request additional resources from the cluster of Edge nodes to run the inference, and this is done through the job queue.\n",
    "\n",
    "To put an item on the job queue, we must first create a bash script that run the workload we want. Run the following cell to create bash script [face_detection_demo.sh](face_detection_demo.sh) which will be our job script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile face_detection_demo.sh\n",
    "#PBS\n",
    "DEVICE=$2\n",
    "FP_MODEL=$3\n",
    "\n",
    "if [ \"$2\" = \"HETERO:FPGA,CPU\" ]; then\n",
    "    # Environment variables and compilation for edge compute nodes with FPGAs\n",
    "    export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/opt/altera/aocl-pro-rte/aclrte-linux64/\n",
    "    source /opt/fpga_support_files/setup_env.sh\n",
    "    aocl program acl0 /opt/intel/computer_vision_sdk/bitstreams/a10_vision_design_bitstreams/5-0_PL1_FP11_ResNet.aocx\n",
    "fi\n",
    "\n",
    "cd $PBS_O_WORKDIR\n",
    "export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/opt/intel/computer_vision_sdk/deployment_tools/inference_engine/samples/build/intel64/Release/lib/ \n",
    "MODEL_ROOT=/opt/intel/computer_vision_sdk/deployment_tools/intel_models\n",
    "./smart_city_tutorial -i data/video82.mp4 \\\n",
    "-m_vp ${MODEL_ROOT}/person-vehicle-bike-detection-crossroad-0078/${FP_MODEL}/person-vehicle-bike-detection-crossroad-0078.xml \\\n",
    "-d_vp ${DEVICE} -n_async 16 -tracking -collision -no_show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put this script on the job queue, we use the command `qsub`.\n",
    "There are two important arguments we use with this command.\n",
    "\n",
    "First, the `-l` flag.\n",
    "This flag is used to specify what type of resources to request from the cluster.\n",
    "For example this can be used to request an Intel® Xeon® CPU based system, or it can be used to request a system with an FPGA accelerator card in it.\n",
    "The syntax is `-l nodes=1:<tag>` where `<tag>` is the descriptor tag for the resource you want.\n",
    "For example, `-l nodes=1:iei-tank-xeon` will request an Intel® Xeon® system.\n",
    "To see the list of available tags, and the number of avilable systems, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     49      properties = compnode,iei,tank-870,intel-core,i5-6500te,skylake,intel-hd-530,8gb,1gbe\r\n",
      "     11      properties = compnode,iei,tank-870,intel-core,i5-6500te,skylake,intel-hd-530,8gb,1gbe,hddl-f,iei-mustang-f100-a10\r\n",
      "     15      properties = compnode,iei,tank-870,intel-core,i5-6500te,skylake,intel-hd-530,8gb,1gbe,hddl-r,iei-mustang-v100-mx8\r\n",
      "      4      properties = compnode,iei,tank-870,intel-core,i5-6500te,skylake,intel-hd-530,8gb,1gbe,ncs,intel-ncs\r\n",
      "     12      properties = compnode,iei,tank-870,intel-core,i5-6500te,skylake,intel-hd-530,8gb,1gbe,ncs,intel-ncs2\r\n",
      "     10      properties = compnode,iei,tank-870,intel-core,i5-7500t,kaby-lake,intel-hd-630,8gb,1gbe\r\n",
      "     14      properties = compnode,iei,tank-870,intel-xeon,e3-1268l-v5,skylake,intel-hd-p530,32gb,1gbe\r\n",
      "      1      properties = compnode,jwip,intel-atom,e3950,apollo-lake,intel-hd-505,4gb,1gbe\r\n",
      "      1      properties = compnode,jwip,intel-core,i5-7500,kaby-lake,intel-hd-630,8gb,1gbe\r\n",
      "     15      properties = compnode,up-squared,grove,intel-atom,e3950,apollo-lake,intel-hd-505,4gb,1gbe\r\n"
     ]
    }
   ],
   "source": [
    "!pbsnodes | grep compnode | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then there is the `-F` flag, which is used to pass in arguments to the job script.\n",
    "The [face_detection_demo.sh](face_detection_demo.sh) takes in 2 arguments:\n",
    "1) the path to the video to run inference on\n",
    "2) targeted device (CPU,GPU,MYRIAD)\n",
    "The job scheduler will use the contents of `-F` flag as the argument to the job script.\n",
    "\n",
    "The following line will request an Intel Xeon system, and passes in \"faces-recognition-walking.mp4 CPU\" to the job script. Run the cell to submit this job. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with an Intel® Core™ CPU\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a \n",
    "    href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel \n",
    "    Core i5-6500TE</a>. The inference workload will run on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Submitting job to Intel Core CPU...\")\n",
    "#Submit job to the queue\n",
    "job_id_core = !qsub smart_city_demo.sh -l nodes=1:iei-tank-core -F \"CPU FP32\"\n",
    "print(job_id_core[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with Intel® Xeon® CPU\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a \n",
    "    href=\"https://ark.intel.com/products/88178/Intel-Xeon-Processor-E3-1268L-v5-8M-Cache-2-40-GHz-\">Intel \n",
    "    Xeon Processor E3-1268L v5</a>. The inference workload will run on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Submitting job to Intel Xeon CPU...\")\n",
    "#Submit job to the queue\n",
    "job_id_xeon = !qsub smart_city_demo.sh -l nodes=1:iei-tank-xeon -F \"CPU FP32\"\n",
    "print(job_id_xeon[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you should see a output like \"{job_id}.c003\", where {job_id} is a number.\n",
    "This is your job ID, and this value can be used to check on the progress of the job down the line.\n",
    "Furthermore, the above job script has been written so that it uses its job_id as the name of the output video.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One bigadvantage of the Job queue system is that you may submit multiple jobs at once. \n",
    "These jobs will be run as soon as resources are available, and may all run at once if the cluster is not busy.\n",
    "Here are few other \"preset\" jobs that for your convenience that you can run. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with Intel® Core™ CPU and using the onboard Intel GPU\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel Core i5-6500TE</a>. The inference workload will run on the Intel® HD Graphics 530 card integrated with the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Submitting job to Intel Core CPU with Intel GPU...\")\n",
    "#Submit job to the queue\n",
    "job_id_gpu = !qsub smart_city_demo.sh -l nodes=1:iei-tank-core -F \"GPU FP32\"\n",
    "print(job_id_gpu[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with  IEI Mustang-F100-A10 (Intel® Arria® 10 FPGA)\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel Core i5-6500te CPU</a> . The inference workload will run on the <a href=\"https://www.ieiworld.com/mustang-f100/en/\"> IEI Mustang-F100-A10 </a> card installed in this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Submitting job to node with Intel FPGA HDDL-F...\")\n",
    "#Submit job to the queue\n",
    "job_id_fpga = !qsub smart_city_demo.sh -l nodes=1:iei-tank-fpga -F \"HETERO:FPGA,CPU FP32\"\n",
    "print(job_id_fpga[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with Intel® Movidius™ Neural Compute Stick\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel Core i5-6500te CPU</a>. The inference workload will run on an <a \n",
    "    href=\"https://software.intel.com/en-us/movidius-ncs\">Intel \n",
    "    Movidius Neural Compute Stick</a> installed in this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Submitting job to node with Intel Movidius NCS...\")\n",
    "#Submit job to the queue\n",
    "job_id_ncs = !qsub smart_city_demo.sh -l nodes=1:tank-870:i5-6500te:intel-ncs -F \"MYRIAD FP16\"\n",
    "print(job_id_ncs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with Intel® Movidius™ Neural Compute Stick 2\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel Core i5-6500te CPU</a>. The inference workload will run on an <a \n",
    "    href=\"https://software.intel.com/en-us/neural-compute-stick\">Intel Neural Compute Stick 2</a> installed in this  node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Submitting job to node with Intel NCS2...\")\n",
    "#Submit job to the queue\n",
    "job_id_ncs2 = !qsub smart_city_demo.sh -l nodes=1:tank-870:i5-6500te:intel-ncs2 -F \"MYRIAD FP16\"\n",
    "print(job_id_ncs2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with  IEI Mustang-V100-MX8 ( Intel® Movidius™ Myriad™ X Vision Processing Unit (VPU))\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel Core i5-6500te CPU</a>. The inference workload will run on an <a \n",
    "    href=\"https://www.ieiworld.com/mustang-v100/en/\">IEI Mustang-V100-MX8 </a>accelerator installed in this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submit job to the queue\n",
    "job_id_vpu = !qsub smart_city_demo.sh -l nodes=1:tank-870:i5-6500te:iei-mustang-v100-mx8 -F \"HDDL FP16\"\n",
    "print(job_id_vpu[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with UP Squared Grove IoT Development Kit (UP2)\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/up-squared-grove-dev-kit\">UP Squared Grove IoT Development Kit</a> edge node with an <a \n",
    "    href=\"https://ark.intel.com/products/96488/Intel-Atom-x7-E3950-Processor-2M-Cache-up-to-2-00-GHz-\">Intel Atom® x7-E3950 Processor</a>. The inference  workload will run on the integrated Intel® HD Graphics 505 card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submit job to the queue\n",
    "job_id_up2 = !qsub smart_city_demo.sh -l nodes=1:up-squared -F \"GPU FP32\"\n",
    "print(job_id_up2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `qstat` command is used to track the progress of the jobs. \n",
    "We have provided a utility funtion \"liveQstat()\" that provide a live updating GUI for you.\n",
    "Run the following cell to check on the progress of your earlier jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liveQstat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the jobs are done. The following cell can be used to display the output. \n",
    "The videoHTML is a utility function provided in [demoutils.py](demoutils.py).\n",
    "This takes one argument, which is the path to the video (see above for convention for the path name).\n",
    "\n",
    "For your convenience we have stored the jobid from the above `qsub` commands, and the following cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoHTML('IEI Tank (Intel Core CPU)', \n",
    "          ['results/output_' + job_id_core[0] + '.mp4'], \n",
    "          'results/stats_'+job_id_core[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoHTML('IEI Tank Xeon (Intel Xeon CPU)',\n",
    "          ['results/output_'+job_id_xeon[0]+'.mp4'],\n",
    "          'results/stats_'+job_id_xeon[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoHTML('IEI Intel GPU (Intel Core + Onboard GPU)', \n",
    "          ['results/output_'+job_id_gpu[0]+'.mp4'],\n",
    "          'results/stats_'+job_id_gpu[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoHTML('IEI Tank + IEI Mustang-F100-A10 (Intel® Arria® 10 FPGA)',\n",
    "          ['results/output_'+job_id_fpga[0]+'.mp4'],\n",
    "          'results/stats_'+job_id_fpga[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoHTML('IEI Tank + Intel CPU + Intel Movidius NCS',\n",
    "          ['results/output_'+job_id_ncs[0]+'.mp4'],\n",
    "          'results/stats_'+job_id_ncs[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoHTML('IEI Tank + Intel CPU + Intel NCS2',\n",
    "          ['results/output_'+job_id_ncs2[0]+'.mp4'],\n",
    "          'results/stats_'+job_id_ncs2[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoHTML('IEI Tank + IEI Mustang-V100-MX8 (Intel® Movidius™ Myriad™ X Vision Processing Unit (VPU))',\n",
    "          ['results/output_'+job_id_vpu[0]+'.mp4'],\n",
    "          'results/stats_'+job_id_vpu[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoHTML('UP Squared Grove IoT Development Kit (UP2)',\n",
    "          ['results/output_'+job_id_up2[0]+'.mp4'],\n",
    "          'results/stats_'+job_id_up2[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_list = [('core', 'Intel Core\\ni5-6500TE\\nCPU'),\n",
    "             ('xeon', 'Intel Xeon\\nE3-1268L v5\\nCPU'),\n",
    "             ('gpu', ' Intel Core\\ni5-6500TE\\nGPU'),\n",
    "             ('fpga', ' IEI Mustang\\nF100-A10\\nFPGA'),\n",
    "             ('ncs', 'Intel\\nMovidius\\nNCS'),\n",
    "             ('ncs2', 'Intel\\nNCS2'),\n",
    "             ('vpu', ' IEI Mustang\\nV100-MX8\\nVPU'),\n",
    "             ('up2', 'Intel Atom\\nx7-E3950\\nUP2/GPU')]\n",
    "\n",
    "stats_list = []\n",
    "for arch, a_name in arch_list:\n",
    "    if 'job_id_'+arch in vars():\n",
    "        stats_list.append(('results/stats_'+vars()['job_id_'+arch][0]+'.txt', a_name))\n",
    "    else:\n",
    "        stats_list.append(('placeholder'+arch, a_name))\n",
    "\n",
    "summaryPlot(stats_list, 'Architecture', 'Time, seconds', 'Inference Engine Processing Time', 'time' )\n",
    "summaryPlot(stats_list, 'Architecture', 'Frames per second', 'Inference Engine FPS', 'fps' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu)",
   "language": "python",
   "name": "c003-python_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
